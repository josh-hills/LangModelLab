# FigureGPT

## ðŸš§ Project Status: Early Development ðŸš§

FigureGPT is currently in early development. The course structure and initial lessons are being designed, but the project is not yet ready for general use. We appreciate your interest and invite you to star the repository to stay updated on our progress.

## Overview

FigureGPT is an educational project that guides learners through the evolution of language models - from simple statistical approaches to complex multi-modal architectures. Each lesson builds incrementally on previous concepts, providing hands-on experience with increasingly sophisticated models.

The course is designed as a hands-on journey through the following progression:

1. **Bigram Model**: Statistical foundations of language modeling
2. **N-gram Extensions**: Higher-order models and their limitations
3. **Word Embeddings**: Continuous vector representations
4. **Recurrent Networks**: Sequence modeling with RNNs/LSTMs
5. **Transformers**: Self-attention and modern architectures
6. **Multi-modal Models**: Integrating text with other modalities

## Project Goals

- Provide a clear, incremental learning path from basic statistical models to advanced neural architectures
- Offer hands-on coding exercises with well-documented implementations
- Bridge theoretical concepts with practical implementations
- Make complex language model concepts accessible to intermediate Python programmers

## Getting Started

The project is not yet ready for general use. Once initial lessons are available:

1. Clone the repository
2. Install dependencies: `pip install -e .`
3. Navigate to `lessons/01_bigram_model/` to begin
4. Follow the README in each lesson folder for guidance

## License

[MIT License](LICENSE) 